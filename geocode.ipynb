{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10a20c12",
   "metadata": {},
   "source": [
    "# Welcome to bank_geocode demo notebook\n",
    "\n",
    "\n",
    "##### The purpose of this notebook is to map every branch of every public sector bank except SBI in India and to analyse the sort of coverage each bank has.\n",
    "\n",
    "-------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "## Section 1: Getting data on bank branches\n",
    "\n",
    "### Import pre-requisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "338b8f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from joblib import Parallel, delayed\n",
    "import re\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "import folium\n",
    "import warnings\n",
    "from branca.element import Template, MacroElement\n",
    "from utils import find_coord, trim\n",
    "from map_legend import orig_template\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea606245",
   "metadata": {},
   "source": [
    "All data sources have been clearly mentioned and given due credit in the [Data](https://github.com/nrarunkaushik/bank_geocode/tree/main/Data) folder. <br>\n",
    "Import the bank data and see it structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb1af78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.width', None)\n",
    "data = pd.read_excel('./Data/MOF_Data.xlsx')\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cd9aa2",
   "metadata": {},
   "source": [
    "### Bank data preprocessing\n",
    "\n",
    "The data clearly has some preprocessing to be done:\n",
    "- A few columns which are of no importance to this analysis are present and hence will be removed\n",
    "- \"Center\" has additional information about type of administrative domain which will make it difficult to search in open street maps\n",
    "- Searching for every branch individually and doing a URL request call for every address is both time consuming and memory&network intensive\n",
    "- Hence pincodes will be extracted from addresses as much as possible and its geo location will be used here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44aaad87",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['S.No.','Part1 Code', 'Part2 Code','Date of Open', 'AD Category', 'License No.', 'License Date'],axis=1,inplace=True)\n",
    "\n",
    "center = Parallel(n_jobs=-1)(delayed(\n",
    "    lambda x: re.split(r' \\(', x)[0]\n",
    ")(data.loc[row,'Center']) for row in data.index)\n",
    "data['Center'] = center\n",
    "\n",
    "pins = Parallel(n_jobs=-1)(delayed(\n",
    "    lambda x: int(re.findall(r'([1-9]\\d{2}\\s{0,1}\\d{3})',x)[-1].replace(\" \", \"\")) if len(re.findall(r'([1-9]\\d{2}\\s{0,1}\\d{3})',x)) > 0 else 0\n",
    ")(data.loc[row,'Address']) for row in data.index)\n",
    "data['pincode'] = pins\n",
    "\n",
    "data['pincode'].apply(lambda x: len(str(x))).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb1bd9e",
   "metadata": {},
   "source": [
    "This shows that there are 135 observations for which pincode is missing. So geolocation for those observations has to be found ot using url requests to openstreetmap.\n",
    "\n",
    "------------------------------------------------------------------------------------------------------------------\n",
    "Cleaned data is saved for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f27fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('./Outputs/docs/Bankdata.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0f1859",
   "metadata": {},
   "source": [
    "## Section 2: Getting geo locations for Indian pincodes\n",
    "\n",
    "Data for pincodes with latitude and longitude are sourced from multiple locations and pooled to make a comprehensive database of indian pincodes with their geocode/geolocation (i.e, latitude and longitude).\n",
    "<br>\n",
    "These data were of course in need of preprocessing, data cleaning and data mining for those pincodes and their geolocation to be extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777c4218",
   "metadata": {},
   "outputs": [],
   "source": [
    "pindata = pd.read_csv('pincodes.csv')\n",
    "pindata2 = pd.read_csv('pincodes2.csv')\n",
    "pindata3 = pd.read_csv('pincodes3.csv')\n",
    "\n",
    "pindata = pindata.loc[pindata['latitude'].dropna().index,]\n",
    "pindata['officename'] = [trim(x) for x in list(pindata.officename.unique())]\n",
    "pindata2['pincode'] = pindata2['key'].apply(lambda x: int(x[3:]))\n",
    "pindata2 = pindata2[['pincode','place_name', 'admin_name1', 'latitude', 'longitude']]\n",
    "pindata = pindata[['pincode','officename', 'circlename', 'latitude', 'longitude']]\n",
    "pindata.columns = pindata2.columns\n",
    "pindata = pindata.loc[~pindata['pincode'].isin(pindata2['pincode'])]\n",
    "pindata = pd.concat([pindata2, pindata], ignore_index=True)\n",
    "\n",
    "pindata3.columns = ['V'+str(i) for i in pindata3.columns]\n",
    "pindata3_new = pindata3.loc[~pindata3['V1'].isin(pindata['pincode'])]\n",
    "pindata3_new = pd.DataFrame([g[1].sort_values(by='V11',ascending=False).values[0] for g in pindata3_new.groupby('V1')],columns=pindata3_new.columns)\n",
    "pindata3_new = pindata3_new[['V1','V2','V3','V9','V10']]\n",
    "pindata3_new.columns = pindata.columns\n",
    "pindata = pd.concat([pindata, pindata3_new], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d7a992",
   "metadata": {},
   "source": [
    " Once the data is cleaned, extracted and pooled, it is saved for future use. <br>\n",
    " ##### Disclaimer:\n",
    " Even with multiple data sources, there were some pincodes for which their geolocation was still missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1763199b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pindata.columns = ['pincode', 'place_name', 'state_name', 'latitude', 'longitude']\n",
    "pindata.to_csv('./Outputs/docs/indian_pincode_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c77289",
   "metadata": {},
   "source": [
    "## Section 3: Merging bank branch data with pincode data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461c4ff5",
   "metadata": {},
   "source": [
    "- Bank data has pincode column with all other columns containing info on each branch. Pincode data also has pincode with columns for latitude and longitude.\n",
    "- To get latitude and longitude for all branches in bank data for whose pincode had their geolocation in pincode data, bank data & pin data has to be left merged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575eba5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "joindata = pd.merge(data, pindata[['latitude', 'longitude', 'pincode']], on='pincode', how='left')\n",
    "joindata.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824007e7",
   "metadata": {},
   "source": [
    "In order to further analyse the data for which either:\n",
    "- pincode is missing or\n",
    "- pincode's geolocation is not found <br>\n",
    "\n",
    "the merged data is split based on latitude missingness and the data subset for which it is missing has its lat/long removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a93cac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "latlong_old = joindata.loc[~np.isnan(joindata['latitude']),:]\n",
    "latlong_miss = joindata.loc[np.isnan(joindata['latitude']),:]\n",
    "latlong_miss['ix'] = latlong_miss.index\n",
    "latlong_miss.drop(['latitude','longitude'],axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5339997f",
   "metadata": {},
   "source": [
    "## Section 4: Finding lat/long for those it is mssing\n",
    "\n",
    "### Using OSM\n",
    "\"find_coord\" function from utils is used to do the URL request to find geocode for the lat/long-missing observations. The process is parallelized for efficiency gains in runtime. The function progressively checks for each of below in case earlier did not return anything:\n",
    "1. Address\n",
    "2. Bank name with branch location and center(city) with search filter for banks\n",
    "3. Bank name with branch location and center(city)\n",
    "4. Bank name with branch location and district with search filter for banks\n",
    "5. Bank name with branch location and district\n",
    "6. Branch, center, district, state\n",
    "7. Center, district, state\n",
    "8. District, state<br>\n",
    "\n",
    "If no geocode found for any of the above searches, then NaNs are returned. Also after each search, it is checked whether the result gotten is any is within India's geographic bounding box.<br>\n",
    "This search result is merged with data of lat/long missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfc0973",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = time.time()\n",
    "coord = Parallel(n_jobs=-1,verbose=10)(delayed(find_coord)(joindata.loc[ix,:]) for ix in latlong_miss.index)\n",
    "x2 = time.time()\n",
    "print(x2-x1)\n",
    "\n",
    "df = pd.DataFrame(coord, columns=['ix','lat','long'],dtype='float64')\n",
    "df = df.astype({'ix':int})\n",
    "df.columns = ['ix', 'latitude','longitude']\n",
    "\n",
    "latlong_new = pd.merge(latlong_miss, df, on='ix', how='left')\n",
    "latlong_new.drop(['ix'],axis=1,inplace=True)\n",
    "\n",
    "latlong = pd.concat([latlong_old, latlong_new], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1164606",
   "metadata": {},
   "source": [
    "### Using State\n",
    "\n",
    "However, there were still some observations for which lat/long were NaNs. As a final desparate attempt, those observations are coded with their state's geolocation. <br>\n",
    "In order to do that, the data containing geolocations of state and union territories is cleaned and processed into required format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737c9714",
   "metadata": {},
   "outputs": [],
   "source": [
    "statepin = pd.read_csv('states.csv')\n",
    "statepin['States'] = statepin.States.apply(lambda x: re.split(r' \\(', x)[0].upper())\n",
    "\n",
    "statepin.loc[statepin['States']=='ANDAMAN AND NICOBAR','States'] = 'ANDAMAN & NICOBAR ISLANDS'\n",
    "statepin.loc[statepin['States']=='DELHI','States'] = 'NCT OF DELHI'\n",
    "\n",
    "statepin = statepin.astype({'Latitude':float,'Longitude':float})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e210e8",
   "metadata": {},
   "source": [
    "For each state-wise group of observations for which lat/long were missing, their state's geolocation is imputed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d03c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for state,group in latlong.loc[np.isnan(latlong['latitude']),:].groupby('State'):\n",
    "    for ind in group.index:\n",
    "        latlong.loc[ind,'latitude'] = statepin.loc[statepin['States']==state,'Latitude'].values[0]\n",
    "        latlong.loc[ind,'longitude'] = statepin.loc[statepin['States']==state,'Longitude'].values[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9904efed",
   "metadata": {},
   "source": [
    "The final data of all bank branches with their pincodes, laititude and longitude is saved for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374cf473",
   "metadata": {},
   "outputs": [],
   "source": [
    "latlong.to_csv('./Outputs/docs/latlong.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1483e264",
   "metadata": {},
   "source": [
    "## Section 5: Mapping (finally!)\n",
    "\n",
    "Each branch is mapped using a different color on an interactive map created using Folium. In addition to that, an additional feature included here is the legend which shows branch numbers by bank and by state inside the map itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74009b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "colordict = {'UCO BANK':'black',\n",
    "             'CENTRAL BANK OF INDIA':'green',\n",
    "             'BANK OF INDIA':'lime',\n",
    "             'CANARA BANK':'blue',\n",
    "             'UNION BANK OF INDIA':'yellow', \n",
    "             'PUNJAB NATIONAL BANK':'gold',\n",
    "             'BANK OF BARODA':'grey',\n",
    "             'INDIAN BANK':'purple',\n",
    "             'INDIAN OVERSEAS BANK':'orange',\n",
    "             'BANK OF MAHARASHTRA':'maroon',\n",
    "             'PUNJAB AND SIND BANK':'turquoise',\n",
    "             'JAMMU & KASHMIR BANK LTD':'red'\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e8b0ca",
   "metadata": {},
   "source": [
    "Map is created bank wise and in the legend, number of branches in each state is also shown for top 15 states and saved in Outputs folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425eeeb3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for bank in colordict.keys():\n",
    "    branches = folium.Map()\n",
    "    datasub = latlong.loc[latlong['Bank']==bank,['State', 'District','Bank', 'Branch','latitude', 'longitude']]\n",
    "    branches.fit_bounds([[6.46,68.11], [35.52, 97.4]])\n",
    "\n",
    "    bank_div = datasub.groupby('Bank').count()['Branch'].sort_values(ascending=False)\n",
    "    bank_str = ''\n",
    "    for b in bank_div.index:\n",
    "        bank_str += \"\"\"<li><span style='background:%s;opacity:0.7;'></span>%s</li>\"\"\"%(colordict[b],b+'(%d)'%(bank_div[b]))\n",
    "\n",
    "    state_div = datasub.groupby('State').count()['Branch']\n",
    "    others = state_div.sum() - state_div.sort_values(ascending=False)[:14].sum()\n",
    "    state_div = state_div.sort_values(ascending=False)[:14]\n",
    "    if others != 0:\n",
    "        state_div['Others'] = others\n",
    "    state_str = ''\n",
    "    for s in state_div.index:\n",
    "        state_str += \"\"\"<li><span style='background:linen;opacity:0.7;'></span>%s</li>\"\"\"%(s+'(%d)'%(state_div[s]))\n",
    "\n",
    "    macro = MacroElement()\n",
    "    template = orig_template\n",
    "    template = template.replace('toreplacetitle',bank+\" Branches\")\n",
    "    template = template.replace('toreplace1',bank_str)\n",
    "    template = template.replace('toreplace2',state_str)\n",
    "    macro._template = Template(template)\n",
    "    \n",
    "    if len(datasub) > 5000:\n",
    "        datasub = datasub.drop_duplicates(subset=['latitude','longitude'])\n",
    "    for i in datasub.values:\n",
    "        folium.CircleMarker(location=[i[4],i[5]],\n",
    "                            radius=2,\n",
    "                            popup=i[3] + ', ' + i[1] + ', ' + i[0],\n",
    "                            color='b',\n",
    "                            key_on = i[2],\n",
    "                            fill_color=colordict[i[2]],\n",
    "                            fill=True,\n",
    "                            fill_opacity=0.7\n",
    "                           ).add_to(branches)\n",
    "   \n",
    "    \n",
    "    branches.get_root().add_child(macro)\n",
    "    branches.save('./Outputs/maps/Bankwise/'+bank+'.html')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa41153b",
   "metadata": {},
   "source": [
    "Map is created state wise and in the legend, number of branches across each is also shown. All maps are saved in Outputs folder for easy access later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c01c298",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for state in latlong.State.unique():\n",
    "    branches = folium.Map()\n",
    "    datasub = latlong.loc[latlong['State']==state,['State', 'District','Bank', 'Branch','latitude', 'longitude']]\n",
    "    branches.fit_bounds([[datasub.latitude.min(),datasub.longitude.min()], [datasub.latitude.max(), datasub.longitude.max()]])\n",
    "\n",
    "    bank_div = datasub.groupby('Bank').count()['Branch'].sort_values(ascending=False)\n",
    "    bank_str = ''\n",
    "    for b in bank_div.index:\n",
    "        bank_str += \"\"\"<li><span style='background:%s;opacity:0.7;'></span>%s</li>\"\"\"%(colordict[b],b+'(%d)'%(bank_div[b]))\n",
    "\n",
    "    state_div = datasub.groupby('State').count()['Branch']\n",
    "    others = state_div.sum() - state_div.sort_values(ascending=False)[:14].sum()\n",
    "    state_div = state_div.sort_values(ascending=False)[:14]\n",
    "    if others != 0:\n",
    "        state_div['Others'] = others\n",
    "    state_str = ''\n",
    "    for s in state_div.index:\n",
    "        state_str += \"\"\"<li><span style='background:linen;opacity:0.7;'></span>%s</li>\"\"\"%(s+'(%d)'%(state_div[s]))\n",
    "\n",
    "    macro = MacroElement()\n",
    "    template = orig_template\n",
    "    template = template.replace('toreplacetitle',state+\" Bank Branches\")\n",
    "    template = template.replace('toreplace1',bank_str)\n",
    "    template = template.replace('toreplace2',state_str)\n",
    "    macro._template = Template(template)\n",
    "    if len(datasub) > 5000:\n",
    "        datasub = datasub.drop_duplicates(subset=['latitude','longitude'])\n",
    "    for i in datasub.values:\n",
    "        folium.CircleMarker(location=[i[4],i[5]],\n",
    "                            radius=2,\n",
    "                            popup=i[3] + ', ' + i[1] + ', ' + i[0],\n",
    "                            color='b',\n",
    "                            key_on = i[2],\n",
    "                            fill_color=colordict[i[2]],\n",
    "                            fill=True,\n",
    "                            fill_opacity=0.7\n",
    "                           ).add_to(branches)\n",
    "    \n",
    "    branches.get_root().add_child(macro)\n",
    "    branches.save('./Outputs/maps/Statewise/'+state+'.html')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfbe3af",
   "metadata": {},
   "source": [
    "Finally, a combined map is created for whole of India across all of the banks. \n",
    "##### Disclaimer:\n",
    "Since this data is huge for an interactive map to handle, observations with lat/long duplicates are dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a9946a",
   "metadata": {},
   "outputs": [],
   "source": [
    "branches = folium.Map()\n",
    "\n",
    "branches.fit_bounds([[6.46,68.11], [35.52, 97.4]])\n",
    "\n",
    "for i in latlong[['State', 'District','Bank', 'Branch','latitude', 'longitude']].drop_duplicates(subset=['latitude','longitude']).values:\n",
    "    folium.CircleMarker(location=[i[4],i[5]],\n",
    "                        radius=2,\n",
    "                        popup=i[3] + ', ' + i[1] + ', ' + i[0],\n",
    "                        color='b',\n",
    "                        key_on = i[2],\n",
    "                        fill_color=colordict[i[2]],\n",
    "                        fill=True,\n",
    "                        fill_opacity=0.7\n",
    "                       ).add_to(branches)\n",
    "bank_div = latlong.groupby('Bank').count()['Branch'].sort_values(ascending=False)\n",
    "bank_str = ''\n",
    "for b in bank_div.index:\n",
    "    bank_str += \"\"\"<li><span style='background:%s;opacity:0.7;'></span>%s</li>\"\"\"%(colordict[b],b+'(%d)'%(bank_div[b]))\n",
    "\n",
    "state_div = latlong.groupby('State').count()['Branch']\n",
    "others = state_div.sum() - state_div.sort_values(ascending=False)[:14].sum()\n",
    "state_div = state_div.sort_values(ascending=False)[:14]\n",
    "if others != 0:\n",
    "    state_div['Others'] = others\n",
    "state_str = ''\n",
    "for s in state_div.index:\n",
    "    state_str += \"\"\"<li><span style='background:linen;opacity:0.7;'></span>%s</li>\"\"\"%(s+'(%d)'%(state_div[s]))\n",
    "\n",
    "macro = MacroElement()\n",
    "template = orig_template\n",
    "template = template.replace('toreplacetitle',\"Bank Branches of India\")\n",
    "template = template.replace('toreplace1',bank_str)\n",
    "template = template.replace('toreplace2',state_str)\n",
    "macro._template = Template(template)\n",
    "branches.get_root().add_child(macro)\n",
    "branches.save('./Outputs/maps/OVERALL.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7918862",
   "metadata": {},
   "source": [
    "Run this cell below to see the interactive map of branches across all states and banks. It is not shown here due to its increase in file size of this Jupyter notebook so a screenshot of it is included here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105f9209",
   "metadata": {},
   "outputs": [],
   "source": [
    "branches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365c9600",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "img_PIL = Image.open(r'./Outputs/maps/overall.png')\n",
    "display(img_PIL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e812e78a",
   "metadata": {},
   "source": [
    "## Section 6: Saving results\n",
    "\n",
    "Plotting in map is fun but getting to know the numbers across states and banks is also necessary. <br>\n",
    "Hence, the following are created:\n",
    "1. Count of branches grouped by 'State','Bank' and 'Population Group\n",
    "2. No. of branches across banks\n",
    "3. No. of branches across states\n",
    "4. No. of branches across banks segregated by area type\n",
    "5. No. of branches across states segregated by area type<br>\n",
    "\n",
    "Area type/Population group divides the locality into Rural, semi urban, urban and metropolitan categories.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec699bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "branch_count = pd.DataFrame([(i[0],i[1],i[2], g.count()['Branch']) for i, g in latlong.groupby(['State','Bank','Population Group'])], columns=['State','Bank','Area_type','#Branches'])\n",
    "branches_statewise = branch_count.groupby('State').sum().sort_values('#Branches',ascending=False)\n",
    "branches_bankwise = branch_count.groupby('Bank').sum().sort_values('#Branches',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bd0885",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_areawise = pd.crosstab(branch_count['Bank'],branch_count['Area_type'],branch_count['#Branches'],aggfunc=sum)\n",
    "bank_areawise['Total'] = bank_areawise.sum(1)\n",
    "bank_areawise.sort_values('Total',ascending=False,inplace=True)\n",
    "bank_areawise = bank_areawise[['Rural', 'Semi-urban', 'Urban','Metropolitan']]\n",
    "bank_areawise.plot(kind='bar',stacked=True, figsize=(15,10), title=\"Bank branches across banks by Area type\", fontsize=10)\n",
    "plt.savefig('./Outputs/plots/Branches_across_banks.png',orientation='landscape',transparent=True,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88d17f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_areawise = pd.crosstab(branch_count['State'],branch_count['Area_type'],branch_count['#Branches'],aggfunc=sum)\n",
    "state_areawise['Total'] = state_areawise.sum(1)\n",
    "state_areawise.sort_values('Total',ascending=False,inplace=True)\n",
    "state_areawise = state_areawise[['Rural', 'Semi-urban', 'Urban','Metropolitan']]\n",
    "state_areawise.plot(kind='bar',stacked=True, figsize=(15,10), title=\"Bank branches over all states by Area type\", fontsize=10)\n",
    "plt.savefig('./Outputs/plots/Branches_across_states.png',orientation='landscape',transparent=True,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc642442",
   "metadata": {},
   "outputs": [],
   "source": [
    "branch_count.to_csv('./Outputs/docs/Branches_count.csv',index=False)\n",
    "branches_statewise.to_csv('./Outputs/docs/Branches_statewise.csv')\n",
    "branches_bankwise.to_csv('./Outputs/docs/Branches_bankwise.csv')\n",
    "bank_areawise.to_csv('./Outputs/docs/Branches_acrossAreatypes_forallBanks.csv')\n",
    "state_areawise.to_csv('./Outputs/docs/Branches_acrossAreatypes_forallStates.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f7198e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
